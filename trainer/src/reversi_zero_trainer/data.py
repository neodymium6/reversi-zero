"""
Training data loading utilities for AlphaZero self-play data.
"""

from pathlib import Path

import numpy as np
import torch
from torch.utils.data import Dataset


class SelfPlayDataset(Dataset):
    """
    Dataset for loading self-play training data generated by Rust backend.

    Expected file structure in data_dir:
    - states.npy: (N, 3, 8, 8) float32 board states
    - policies.npy: (N, 64) float32 MCTS visit distributions
    - values.npy: (N,) float32 game outcomes from perspective of current player

    Args:
        data_dir: Directory containing states.npy, policies.npy, values.npy
    """

    def __init__(self, data_dir: Path | str):
        self.data_dir = Path(data_dir)

        # Load all data into memory (self-play datasets are typically small enough)
        states_path = self.data_dir / "states.npy"
        policies_path = self.data_dir / "policies.npy"
        values_path = self.data_dir / "values.npy"

        if not states_path.exists():
            raise FileNotFoundError(f"States file not found: {states_path}")
        if not policies_path.exists():
            raise FileNotFoundError(f"Policies file not found: {policies_path}")
        if not values_path.exists():
            raise FileNotFoundError(f"Values file not found: {values_path}")

        self.states = np.load(states_path)
        self.policies = np.load(policies_path)
        self.values = np.load(values_path)

        # Validate shapes
        n_samples = len(self.states)
        if len(self.policies) != n_samples:
            raise ValueError(
                f"Mismatch: states has {n_samples} samples, "
                f"but policies has {len(self.policies)}"
            )
        if len(self.values) != n_samples:
            raise ValueError(
                f"Mismatch: states has {n_samples} samples, "
                f"but values has {len(self.values)}"
            )

        # Validate data types and shapes
        if self.states.shape[1:] != (3, 8, 8):
            raise ValueError(
                f"Expected states shape (N, 3, 8, 8), got {self.states.shape}"
            )
        if self.policies.shape[1:] != (64,):
            raise ValueError(
                f"Expected policies shape (N, 64), got {self.policies.shape}"
            )
        if self.values.ndim != 1:
            raise ValueError(f"Expected values shape (N,), got {self.values.shape}")

    def __len__(self) -> int:
        return len(self.states)

    def __getitem__(self, idx: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """
        Returns:
            state: (3, 8, 8) tensor
            policy: (64,) tensor (probability distribution)
            value: scalar tensor (outcome from current player's perspective)
        """
        state = torch.from_numpy(self.states[idx]).float()
        policy = torch.from_numpy(self.policies[idx]).float()
        value = torch.tensor(self.values[idx], dtype=torch.float32)

        return state, policy, value

    def get_stats(self) -> dict[str, float]:
        """Get dataset statistics for logging."""
        return {
            "num_samples": len(self),
            "mean_value": float(self.values.mean()),
            "std_value": float(self.values.std()),
            "positive_values": float((self.values > 0).sum()),
            "negative_values": float((self.values < 0).sum()),
            "zero_values": float((self.values == 0).sum()),
        }
